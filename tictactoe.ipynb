{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35501346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "class QAgent:\n",
    "    def __init__(self):\n",
    "        self.gamma = 0.95  # Discount factor for future rewards\n",
    "        self.epsilon = 1.0  # Initial exploration rate\n",
    "        self.epsilon_min = 0.01  # Minimum exploration rate\n",
    "        self.epsilon_decay = 0.995  # Decay rate for exploration probability\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        model = Sequential([\n",
    "            Dense(64, input_dim=9, activation='relu'),  # Input is the flattened board\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(9, activation='linear')  # Output the Q-values for each action\n",
    "        ])\n",
    "        # Use the class directly instead of the alias string\n",
    "        model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.randint(0, 9)  # Explore action space\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # Exploit learned values\n",
    "\n",
    "    def train(self, state, action, reward, next_state, done):\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "        target_f = self.model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "class TicTacToeEnv:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros(9, dtype=int)\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros(9, dtype=int)\n",
    "        self.done = False\n",
    "        return self.board[np.newaxis, :]\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.board[action] != 0:\n",
    "            return self.board[np.newaxis, :], -10, True  # Penalize invalid moves\n",
    "        self.board[action] = 1  # AI's move\n",
    "        \n",
    "        if self.check_winner(1):\n",
    "            return self.board[np.newaxis, :], 10, True  # AI wins\n",
    "        elif self.check_immediate_threat():\n",
    "            return self.board[np.newaxis, :], 3, False  # AI blocks the player from winning\n",
    "        elif self.check_potential_win_setup(action):\n",
    "            return self.board[np.newaxis, :], 2, False  # AI sets up for a win\n",
    "        \n",
    "        if np.all(self.board != 0):\n",
    "            return self.board[np.newaxis, :], 0, True  # Draw\n",
    "        \n",
    "        self.opponent_move()\n",
    "        \n",
    "        if self.check_winner(-1):\n",
    "            return self.board[np.newaxis, :], -10, True  # AI loses\n",
    "        elif np.all(self.board != 0):\n",
    "            return self.board[np.newaxis, :], 0, True  # Draw\n",
    "        \n",
    "        return self.board[np.newaxis, :], 1, False  # Game continues\n",
    "\n",
    "    def check_immediate_threat(self):\n",
    "        # Check if the opponent was one move away from winning\n",
    "        return self.is_one_move_away(-1)\n",
    "\n",
    "    def check_potential_win_setup(self, action):\n",
    "        # Temporarily make the move\n",
    "        self.board[action] = 1\n",
    "        win_next_move = self.is_one_move_away(1)\n",
    "        self.board[action] = 0  # Reset the move\n",
    "        return win_next_move\n",
    "\n",
    "    def is_one_move_away(self, player):\n",
    "        # Check if 'player' can win in the next move\n",
    "        for combo in [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]:\n",
    "            if sum(self.board[pos] == player for pos in combo) == 2:\n",
    "                if any(self.board[pos] == 0 for pos in combo):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def opponent_move(self):\n",
    "        empty_cells = np.where(self.board == 0)[0]\n",
    "        if len(empty_cells) > 0:\n",
    "            self.board[np.random.choice(empty_cells)] = -1\n",
    "\n",
    "    def check_winner(self, player):\n",
    "        combos = [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]\n",
    "        return any(np.all(self.board[list(line)] == player) for line in combos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c9ced5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the agent or load an existing model\n",
    "should_train = False\n",
    "\n",
    "if should_train:\n",
    "    def train_agent(episodes=1000):\n",
    "        env = TicTacToeEnv()\n",
    "        agent = QAgent()\n",
    "\n",
    "        for e in range(episodes):\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                action = agent.act(state)\n",
    "                next_state, reward, done = env.step(action)\n",
    "                agent.train(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "\n",
    "            if (e + 1) % 100 == 0:\n",
    "                print(f\"Episode {e+1}/{episodes} - Epsilon: {agent.epsilon:.2f}\")\n",
    "\n",
    "        # After training, save the model\n",
    "        agent.model.save('tic_tac_toe_model.h5')\n",
    "        print(\"Model saved successfully.\")\n",
    "\n",
    "    # Initiate training\n",
    "    train_agent(1000)\n",
    "else:\n",
    "    try:\n",
    "        agent = QAgent()  # Ensure agent is defined\n",
    "        # Load the model without needing to specify custom objects for standard cases\n",
    "        agent.model = load_model('tic_tac_toe_model.h5')\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load model. Error:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "134fbe88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7c670a099a41a99ca33a998efbda3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Button(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1accf8de0464499924a984fd6af366e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Reset', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d97b63109c466fb59ad1e9c2e1bb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Close Game', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f556ba3f3f34f938aa89bb4c51b50d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game records saved to game_data.csv\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "\n",
    "class TicTacToeGameGUI:\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self.game_records = [] \n",
    "        self.board = np.zeros(9, dtype=int)\n",
    "        self.buttons = [widgets.Button(description='', button_style='', layout=widgets.Layout(height='60px', width='60px', border='1px solid black')) for _ in range(9)]\n",
    "        for button in self.buttons:\n",
    "            button.on_click(self.on_button_click)\n",
    "        self.output = widgets.Output()\n",
    "        self.reset_button = widgets.Button(description=\"Reset\", button_style='info')\n",
    "        self.reset_button.on_click(self.reset_board)\n",
    "        self.grid = widgets.GridBox(self.buttons, layout=widgets.Layout(grid_template_columns=\"repeat(3, 100px)\"))\n",
    "        self.close_game_button = widgets.Button(description=\"Close Game\", button_style='danger')\n",
    "        self.close_game_button.on_click(self.close_game)\n",
    "        # Modify the display line to include the new button\n",
    "        display(self.grid, self.reset_button, self.close_game_button, self.output)\n",
    "        \n",
    "        self.game_over = False  # Initialize the game_over attribute here\n",
    "\n",
    "    def on_button_click(self, b):\n",
    "        if self.game_over:  # Check if the game is already over\n",
    "            return  # Ignore clicks if the game is over\n",
    "\n",
    "        index = self.buttons.index(b)\n",
    "        if self.board[index] == 0:  # If the cell is empty\n",
    "            self.board[index] = 1  # Player move\n",
    "            self.buttons[index].description = 'X'\n",
    "            self.buttons[index].button_style = 'success'\n",
    "            self.check_game_status()\n",
    "            if not self.game_over:\n",
    "                self.agent_move()\n",
    "\n",
    "    def agent_move(self):\n",
    "        if self.game_over:\n",
    "            return\n",
    "\n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            state = self.board[np.newaxis, :]\n",
    "            action = self.agent.act(state)\n",
    "\n",
    "            # Keep choosing moves until a valid one is made\n",
    "            while self.board[action] != 0:\n",
    "                print(f\"Invalid move attempted at {action}. Retrying.\")\n",
    "                action = self.agent.act(state)\n",
    "\n",
    "            # Make the move\n",
    "            self.board[action] = -1\n",
    "            self.buttons[action].description = 'O'\n",
    "            self.buttons[action].button_style = 'danger'\n",
    "            self.check_game_status()\n",
    "\n",
    "    def record_game(self, game_id, winner, moves):\n",
    "        self.game_records.append({\n",
    "            'game_id': game_id,\n",
    "            'winner': winner,\n",
    "            'moves': moves\n",
    "        })\n",
    "\n",
    "    def save_game_records(self, filename='game_data.csv'):\n",
    "        df = pd.DataFrame(self.game_records)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Game records saved to {filename}\")\n",
    "\n",
    "\n",
    "    # Update your game status check to record each game\n",
    "    def check_game_status(self):\n",
    "        winner = self.check_winner()\n",
    "        if winner or np.all(self.board != 0):\n",
    "            self.game_over = True\n",
    "            winner_label = 'draw' if not winner else 'player' if winner == 1 else 'agent'\n",
    "            result = \"It's a draw!\" if not winner else (\"You win!\" if winner == 1 else \"You lose!\")\n",
    "            with self.output:\n",
    "                clear_output(wait=True)\n",
    "                print(result)\n",
    "            # Record this game's outcome\n",
    "            self.record_game(game_id=np.random.randint(1000, 9999), winner=winner_label, moves=np.count_nonzero(self.board))\n",
    "        else:\n",
    "            self.game_over = False\n",
    "\n",
    "\n",
    "    def check_winner(self):\n",
    "        combos = [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]\n",
    "        for player in [1, -1]:\n",
    "            for combo in combos:\n",
    "                if np.all(self.board[list(combo)] == player):\n",
    "                    return player\n",
    "        return None\n",
    "\n",
    "    def reset_board(self, b=None):\n",
    "        self.board = np.zeros(9, dtype=int)  # Reset the internal game board\n",
    "        for button in self.buttons:\n",
    "            button.description = ''  # Clear text - this should clear the \"X\" and \"O\" from the buttons\n",
    "            button.button_style = ''  # Clear style\n",
    "            button.disabled = False   # Re-enable the button if it was disabled\n",
    "        self.game_over = False  # Ensure the game state is reset\n",
    "        with self.output:\n",
    "            clear_output(wait=True)  # Clear any messages displayed\n",
    "            \n",
    "    def close_game(self, b):\n",
    "        # Save game records to a CSV file\n",
    "        self.save_game_records()\n",
    "        # Disable all buttons to stop the game\n",
    "        for button in self.buttons:\n",
    "            button.disabled = True\n",
    "        self.reset_button.disabled = True\n",
    "        self.close_game_button.disabled = True\n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Game has been closed and data saved.\")\n",
    "\n",
    "\n",
    "# Create and display the game GUI\n",
    "agent = QAgent()  # Assuming the agent is defined and the model is loaded\n",
    "game_gui = TicTacToeGameGUI(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb4500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
